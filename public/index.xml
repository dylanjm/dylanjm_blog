<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Uninformed Priors</title>
    <link>/</link>
    <description>Recent content on Uninformed Priors</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>dylan.mcdowell226@gmail.com (Dylan McDowell)</managingEditor>
    <webMaster>dylan.mcdowell226@gmail.com (Dylan McDowell)</webMaster>
    <lastBuildDate>Mon, 16 Apr 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About Me</title>
      <link>/about/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      <author>dylan.mcdowell226@gmail.com (Dylan McDowell)</author>
      <guid>/about/</guid>
      <description>Hello, my name is Dylan James McDowell. I am Financial Economics undergraduate with hopes to pursue a graduate degree in Mathematical Statistics with a research focus in Bayesian Methods &amp;amp; Decision Theory. I love coding in #rstats and #python and currently am learning Stan. I love to read, write, and have #woahdude deep discussions with friends. I named this blog “Uninformed Priors” because 1) I’m really interested in Bayesian Statistics and 2) It desribes the way I often approach life with an open mind.</description>
    </item>
    
    <item>
      <title>Tidy Tuesday Week 01</title>
      <link>/posts/tidy-tuesday-week-01/</link>
      <pubDate>Mon, 16 Apr 2018 00:00:00 +0000</pubDate>
      <author>dylan.mcdowell226@gmail.com (Dylan McDowell)</author>
      <guid>/posts/tidy-tuesday-week-01/</guid>
      <description>Here are some R libraries we will need to reproduce the plots for this week’s #TidyTuesday
library(tidyverse) library(readxl) library(albersusa) library(ggthemes)  Background The online community, R for Data Science, has started what’s called #TidyTuesday. Every week they post a new dataset along with an original graphic and challenge people to either 1) recreate the plot or 2) create their own take on the data. For the very first challenge, they posted a data set on student tuition across the United States.</description>
    </item>
    
  </channel>
</rss>